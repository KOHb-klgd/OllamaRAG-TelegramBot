import os
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_ollama import ChatOllama
from langchain_core.messages import HumanMessage
from typing import Optional
from config import Config, logger


def get_index_db() -> Optional[FAISS]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö."""
    embeddings = HuggingFaceEmbeddings(model_name="intfloat/multilingual-e5-large")
    db_file_name = "db/db_01"

    if os.path.exists(f"{db_file_name}/index.faiss"):
        return FAISS.load_local(db_file_name, embeddings, allow_dangerous_deserialization=True)
    logger.warning("–í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
    return None


async def generate_response(query: str, use_context: bool = False) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    llm = ChatOllama(model=Config.OLLAMA_MODEL, temperature=0)

    if use_context:
        db = get_index_db()
        if db:
            docs = db.similarity_search(query, k=3)
            context = []
            for i, doc in enumerate(docs, start=1):
                source = doc.metadata.get("source", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫")
                section = doc.metadata.get("section", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–∞–∑–¥–µ–ª")
                content = doc.page_content[:500]  # –û–≥—Ä–∞–Ω–∏—á–∏–º –¥–ª–∏–Ω—É —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
                context.append(
                    f"üìÑ **–ò—Å—Ç–æ—á–Ω–∏–∫:** {source}\n"
                    f"üîñ **–†–∞–∑–¥–µ–ª:** {section}\n"
                    f"üìù **–ü–∞—Ä–∞–≥—Ä–∞—Ñ {i}:** {content}\n\n"
                )
            context_text = "\n".join(context)
            prompt = (
                f"""–¢—ã —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ –¥–∞–≤–∞—Ç—å –æ—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã. 
            –í–æ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å: {context_text}\n\n
            –í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –ø–æ–¥—É–º–∞–π –Ω–∞–¥ –ø—Ä–∏–≤–µ–¥–µ–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º. 
            –¢–µ–ø–µ—Ä—å –ø—Ä–æ—Å–º–æ—Ç—Ä–∏ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {query}\n
            –î–∞–π –æ—Ç–≤–µ—Ç –Ω–∞ —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å, –∏—Å–ø–æ–ª—å–∑—É—è –≤—ã—à–µ—É–∫–∞–∑–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
            –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–Ω—è—Ç–µ–Ω –º–∞–ª–µ–Ω—å–∫–æ–º—É —Ä–µ–±—ë–Ω–∫—É –∏ –ª–∏—Ü–∞–º —Å–æ —Å–ª–∞–±–æ—É–º–∏–µ–º.
            –¢—ã –º–æ–∂–µ—à—å –∑–∞–¥–∞–≤–∞—Ç—å –ª—é–±—ã–µ –Ω–∞–≤–æ–¥—è—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —á—Ç–æ–±—ã –ø–æ–≤—ã—Å–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å. 
            –í—Å–µ–≥–¥–∞ –¥–∞–≤–∞–π –ø–æ–ª–Ω—ã–π –∏ —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å.
            –û—Ç–≤–µ—Ç:"""
            )
            try:
                response = await llm.agenerate([[HumanMessage(content=prompt)]])
                logger.info(f"–û—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: {query}")
                return f"{context_text}\n\n–û—Ç–≤–µ—Ç:\n{response.generations[0][0].text}"
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
                return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}"
        else:
            logger.warning("–í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
            return "‚ö†Ô∏è –í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞."
    else:
        try:
            response = await llm.agenerate([[HumanMessage(content=query)]])
            logger.info(f"–û—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: {query}")
            return response.generations[0][0].text
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {e}")
            return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {e}"
